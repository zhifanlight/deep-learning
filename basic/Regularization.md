<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script>

# 正则化

## 背景介绍

- 对训练模型的权值项进行约束，以防止过拟合，保证更好的泛化性能

## 常用方法

### \\(L\_{0}\\) 正则化

$$||w||\_{0} = \sum\_{i=1}^{N}I(w\_{i} \neq 0)$$

- 通过 \\(L\_{0}\\) 范数进行约束，使向量中大部分元素都是 \\(0\\)，即权值稀疏

- 由于 \\(L\_{0}\\) 范数难以优化求解，通常用其最优凸近似 \\(L\_{1}\\) 范数代替

### \\(L\_{1}\\) 正则化

$$||w||\_{1} = \sum\_{i=1}^{N}|w\_{i}|$$

- 通过 \\(L\_{1}\\) 范数进行约束，使向量中大部分元素都是 \\(0\\)，即权值稀疏

- 导数固定，在使用梯度下降求解时：

	- 如果 \\(w\_{i} < 0\\)，导数为 \\(-1\\)，\\(w\_{i}\\) 减去 \\(-\lambda\\) 使 \\(w\_{i}\\) 变大

	- 如果 \\(w\_{i} > 0\\)，导数为 \\(1\\)，\\(w\_{i}\\) 减去 \\(\lambda\\) 使 \\(w\_{i}\\) 变小

	- 由于 \\(w\_{i}\\) 改变量始终不变，最终向量中大部分元素是 \\(0\\)

### \\(L\_{2}\\) 正则化

$$||w||\_{2} = \sum\_{i=1}^{N} w\_{i}^{2}$$

- 通过 \\(L\_{2}\\) 范数进行约束，使向量中大部分元素都接近 \\(0\\)，即权值衰减

- 导数为 \\(2w\_{i}\\)，在使用梯度下降求解时：

	- 如果 \\(w\_{i} < 0\\)，导数为负，\\(w\_{i}\\) 减去 \\(2\lambda w\_{i}\\) 使 \\(w\_{i}\\) 变大

	- 如果 \\(w\_{i} > 0\\)，导数为正，\\(w\_{i}\\) 减去 \\(2\lambda w\_{i}\\) 使 \\(w\_{i}\\) 变小

	- 当 \\(|w\_{i}| \rightarrow 0\\)，\\(w\_{i}\\) 改变量越来越小，最终向量中大部分元素都接近 \\(0\\)

### max-norm 正则化

$$||w||\_{2} \leq c$$

- \\(L\_{2}\\) 范数不超过 \\(c\\)，\\(w\\) 被限制在半径为 \\(c\\) 的超球体内

- 当 \\(||w||\_{2} > c\\) 时，对每一维等比例缩放，以保证 \\(||w||\_{2} = c\\)

- 在一定程度上防止梯度爆炸