# 模型比较

## 回归

- 线性回归

- 回归树

- 最近邻

- 神经网络

- 集成方法

  - $\mathrm{GBDT}$

  - 随机森林

## 分类

- 逻辑回归

- 支持向量机

- 决策树

- $\mathrm{kNN}$

- 朴素贝叶斯

- 线性判别分析

- 神经网络

- 集成方法

  - $\mathrm{Adaboost}$

  - $\mathrm{GBDT}$

  - 随机森林

## 聚类

- 划分聚类

- 层次聚类

- 密度聚类

- 模型聚类

## 决策树

- 参考 [$\mathrm{DecisionTrees.md}$](DecisionTrees.md)

### 优点

- 容易理解和解释，方便可视化分析

- 测试数据集时，运行速度比较快

### 缺点

- 对缺失数据处理比较困难

- 忽略数据集中属性间的相互关联

- 容易出现过拟合

  - 对决策树进行剪枝，使用交叉验证选择最终的树结构

  - 使用基于决策树的组合方法，比如随机森林、$\mathrm{GBDT}$

## $\mathrm{kNN}$

- 参考 [$\mathrm{kNN.md}$](kNN.md)

### 优点

- 理论简单，容易实现

- 在线分类，新数据可以直接加入数据集而不用重新训练

### 缺点

- $k$ 值的选择不易控制

- 样本集较大时，计算量也较大

- 样本不平衡时，预测偏差比较大

## $\mathrm{SVM}$

- 参考 [$\mathrm{SVM.md}$](SVM.md)

### 优点

- 泛化能力强

- 可以处理高维、非线性问题

- 相对于神经网络，没有局部最小值

### 缺点

- 由于模型较大，在数据维度较高时，训练效率低

- 对非线性问题没有通用解决方案，必须谨慎选择核函数

## 逻辑回归

- 参考 [$\mathrm{LogisticRegression.md}$](LogisticRegression.md)

### 优点

- 计算量少，易于实现

- 与 $\mathrm{SVM}$ 相比，可以输出样本的概率值

### 缺点

- 当分类边界非线性时，性能较差

### $\mathrm{LR}$ 与 $\mathrm{SVM}$ 选择

- 数据量过大时：

  - 选择 $\mathrm{LR}$，优化方法采用 $\mathrm{SGD}$；由于内存开销，$\mathrm{SVM}$ 无法在海量数据上训练

- 数据量不是很大时：

  - 使用正则化约束的 $\mathrm{LR}$，或者线性核的 $\mathrm{SVM}$

  - 上述方法无效时，尝试高斯核的 $\mathrm{SVM}$

## 朴素贝叶斯

- 参考 [$\mathrm{NaiveBayes.md}$](NaiveBayes.md)

### 优点

- 模型简单、训练速度快

#### 缺点

- 输入数据不同维度之间有关联时，效果变差

## 神经网络

- 参考 [$\mathrm{BP.md}$](../network/BP.md)

- 参考 [$\mathrm{CNN.md}$](../network/CNN.md)

### 优点

- 分类精度高，学习能力强

### 缺点

- 参数多，训练缓慢

- 黑盒过程，解释性较差

- 有可能陷入局部最小值